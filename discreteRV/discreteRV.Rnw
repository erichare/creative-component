\documentclass[a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{RJournal}
\usepackage{amsmath,amssymb,array,float}
\usepackage{booktabs}

\newcommand{\hh}[1]{{\color{magenta} #1}} 

%% load any required packages here

\begin{document}

%% do not edit, for illustration only
\sectionhead{Contributed research article}
\volume{XX}
\volnumber{YY}
\year{2015}
\month{April}

%% replace RJtemplate with your article
\begin{article}

\title{Manipulation of Discrete Random Variables with discreteRV}
\author{by Eric Hare, Andreas Buja, and Heike Hofmann}

\maketitle

\abstract{
A prominent issue in statistics education is the sometimes large disparity between the theoretical and the computational coursework. \CRANpkg{discreteRV} is an R package for manipulation of discrete random variables which uses clean and familiar syntax similar to the mathematical notation in introductory probability courses. The package offers functions that are simple enough for users with little experienced with statistical programming, but has more advanced features which are suitable for a large number of more complex applications. In this paper, we introduce and motivate \pkg{discreteRV}, describe its functionality, and provide reproducible examples illustrating its use.
}

<<concordance, echo=FALSE>>=
    opts_chunk$set(concordance=TRUE, fig.width=4, fig.height=4)
    opts_knit$set(self.contained=FALSE)
@

<<libraries, echo=FALSE, cache=FALSE, message=FALSE>>=
    library(discreteRV)
    library(MASS)
@

\section{Introduction}

One of the primary hurdles in teaching probability courses in an undergraduate setting is to bridge the gap between theoretical notation from textbooks and lectures, and the statements used in statistical software required in more and more classes. Depending on the background of the student, this missing link can manifest itself differently: some students master theoretical concepts and notation, but struggle with the computing environment, while others are very comfortable with statistical programming, but find it difficult to translate their knowledge back to the theoretical setting of the classroom.

\pkg{discreteRV} is an approach to help with bringing software commands closer to the theoretical notation. The package provides a comprehensive set of functions to create, manipulate, and simulate from discrete random variables. It is designed for introductory probability courses. \pkg{discreteRV} uses syntax that closely matches the notation of standard probability textbooks to allow for a more seamless connection between a probability classroom setting and the use of statistical software. \pkg{discreteRV} is available for download on the Comprehensive R Archive Network (CRAN).

The functions of \pkg{discreteRV} are organized into two logical areas, termed probabilities and simulations.

\section{Probabilities}

\pkg{discreteRV} includes a suite of functions to create, manipulate, and compute distributional quantities for discrete random variables. A list of these functions and brief discriptions of their functionality is available in Table \ref{tbl:discreteRV-probs}.

\begin{table}
\centering
\scalebox{0.95}{
\begin{tabular}{lp{0.8\textwidth}}\hline
Name & Description \\ 
\hline
Creation \\ 
\hline
\code{as.RV} & Turn a probability vector with possible outcome values in the names() attribute into a random variable \\
\code{jointRV} & Create a joint random variable consisting of possible outcome values and their probabilities or odds \\
\code{RV} & Create a random variable consisting of possible outcome values and their probabilities or odds \\
\hline
Manipulation \\ 
\hline
\code{iid} & Returns a random variable with joint probability mass function of random variable $X^n$ \\
\code{independent} & Returns a boolean indicating whether two RVs X and Y are independent \\
\code{joint} & Returns a random variable with joint probability mass function of random variables X and Y \\
\code{marginal} & The specified marginal distribution of a joint random variable \\
\code{margins} & All marginal distributions of a joint random variable \\
\code{SofI} & Sum of independent random variables \\
\code{SofIID} & Sum of independent identically distributed random variables \\
\hline
Probabilities \\ 
\hline
\code{E} & Expected value of a random variable \\
\code{KURT} & Kurtosis of a random variable \\
\code{P} & Calculate probabilities of events \\
\code{probs} & Probability mass function of random variable X \\
\code{SD} & Standard deviation of a random variable \\
\code{SKEW} & Skewness of a random variable \\
\code{V} & Variance of a random variable \\
\hline
Methods \\
\hline 
\code{plot.RV} & Plot a random variable of class RV \\
\code{print.RV} & Print a random variable of class RV \\
\code{qqnorm.RV} & Normal quantile plot for RVs to answer the question how close to normal it is \\

\hline
\end{tabular}}
\caption{\label{tbl:discreteRV-probs} Overview of functions provided in \pkg{discreteRV} ordered by topics.}
\end{table}

\subsection{Creating random variables}
The centerpiece of \pkg{discreteRV} is a set of functions to create and manipulate discrete random variables. A random variable $X$ is defined as a theoretical construct representing the value of an outcome of a random experiment \citep[see e.g.~][]{ws:1999}. A discrete random variable is a special case that can only take on a countable set of values. Discrete random variables are associated with probability mass functions, which map the set of possible values of the random variable to probabilities. Probability mass functions must therefore define probabilities which are between zero and one, and must sum to one. 

Throughout this document, we will work with two random variables, a simple example of a discrete random variable representing the value of a roll of a fair die, and  one representing a realization of a Poisson random variable with mean parameter equal to two. Formally, we can define such random variables and their probability mass functions as follows:

Let $X$ be a random variable representing a single roll of a fair die; i.e., the sample space $\Omega = \{1, 2, 3, 4, 5, 6\}$ and $X$ is the identity, mapping the upturned face of a die roll to the corresponding number of dots visible. Then,

\begin{displaymath}
   f(x) = P(X = x) = \left\{
     \begin{array}{lr}
       1/6 & x \in {1, 2, 3, 4, 5, 6}\\
       0 & \text{otherwise}
     \end{array}
   \right.
\end{displaymath} \\

Let $Y$ be a random variable distributed according to a Poisson distribution with mean parameter $\lambda$. In this case, Y takes on values in the non-negative integers $\{0, 1, 2, ... \}$. Then,

\begin{displaymath}
   f(y) = P(Y = y) = \left\{
     \begin{array}{lr}
       \frac{\lambda^y e^{-\lambda}}{y!} & y \in {0, 1, 2, ...}\\
       0 & \text{otherwise}
     \end{array}
   \right.
\end{displaymath} \\

In \pkg{discreteRV}, a discrete random variable is defined through the use of the \code{RV} function. \code{RV} accepts a vector of outcomes, a vector of probabilities, and returns an \code{RV} object. The code to create X, a random variable representing the roll of a fair die, is as follows:

<<makeRV>>=
(X <- RV(outcomes = 1:6, probs = 1/6))
@

Defaults are chosen to simplify the random variable creation process. For instance, if the \code{probs} argument is left unspecified, \pkg{discreteRV} assumes a uniform distribution. Hence, the following code is equivalent for defining a fair die:

<<makeRVequiv>>=
(X <- RV(1:6))
@

Outcomes can be specified as a range of values, which is useful for distributions in which the outcomes that can occur with non-zero probability are unbounded. This can be indicated with the \code{range} argument, which defaults to TRUE in the event that the range of values includes positive or negative infinity. To define our poisson random variable Y, we specify the outcomes as a range and the probabilities as a function:

<<makeRVpois>>=
pois.func <- function(y, lambda) { return(lambda^y * exp(-lambda) / factorial(y)) }

(Y <- RV(outcomes = c(0, Inf), probs = pois.func, lambda = 2))
@

Several common distributions are natively supported so that the function need not be defined manually. For instance, an equivalent method of defining $Y$ is:

<<makeRVpoisequiv>>=
(Y <- RV("poisson", lambda = 2))
@

The \code{RV} function also allows the definition of a random variable in terms of odds. We construct a loaded die in which a roll of one is four times as likely as any other roll as:

<<makeRVodds>>=
(X.loaded <- RV(outcomes = 1:6, odds = c(4, 1, 1, 1, 1, 1)))
@

\subsection{Structure of an RV object}

The syntactic structure of the included functions lends itself both to a natural presentation of elementary probabilities and properties of probability mass functions in an introductory probability course, as well as more advanced modeling of discrete random variables. In Table \ref{tbl:discreteRV-connect}, we provide an overview of the notational similarities between \pkg{discreteRV} and the commonly used probability textbook by \cite{cb:2001}

\begin{table}
\centering
\scalebox{0.95}{
\begin{tabular}{lp{0.6\textwidth}}\hline
discreteRV & Casella and Berger \\ 
\hline
\code{E(X)} & E(X) \\
\code{P(X == x)} & $P(X = x)$ \\
\code{P(X >= x)} & $P(X \ge x)$ \\
\code{P((X < x1) \%AND\% (X > x2))} & $P(X < x_1 \cap X > x_2)$ \\
\code{P((X < x1) \%OR\% (X > x2))} & $P(X < x_1 \cup X > x_2)$ \\
\code{P((X == x1) | (X > x2))} & $P(X < x_1 | X > x_2)$ \\
\code{probs(X)} & $f(x)$ \\
\code{SD(X)} & $sd(X)$ \\
\code{V(X)} & $var(X)$ \\
\end{tabular}}
\caption{\label{tbl:discreteRV-connect} Probability functions in \pkg{discreteRV} and their corresponding syntax in introductory statistics courses.}
\end{table}

A random variable object is constructed by defining a standard R vector to be the possible outcomes that the random variable can take (the sample space $\Omega$). It is preferred, though not required, that these be encoded as numeric values, since this allows the computation of expected values, variances, and other distributional properties. This vector of outcomes then stores attributes which include the probability of each outcome. By default, the print method for a random variable will display the probabilities as fractions in most cases, aiding in readability. The probabilities can be retrieved as a numeric vector by using the \code{probs} function:

<<probs>>=
probs(X)
@

\subsection{Probability-based calculations}

By storing the outcomes as the principle component of the object X, we can  make a number of probability statements in R. For instance, we can calculate  the probability of obtaining a roll greater than 1 by using the code $P(X > 1)$. R will check which of the values in the vector X are greater than 1. In this case, these are the outcomes 2, 3, 4, 5, and 6. Hence, R will return TRUE for these elements of X, and we compute the probability of this occurrence in the function P by simply summing over the probability values stored in the names of these particular outcomes. Likewise, we can make slightly more complicated probability statements such as $P(X > 5 \cup X = 1)$, using the \code{\%OR\%} and \code{\%AND\%} operators. Consider our Poisson random variable $Y$, and suppose we want to obtain the probability that $Y$ is within a distance $\delta$ of its mean parameter $\lambda = 2$:

<<poisexample>>=
delta <- 3
lambda <- 2

P((Y >= lambda - delta) %AND% (Y <= lambda + delta))
@

Alternatively, we could have also used the slightly more complicated looking expression:

<<poisexample.alt>>=
P((Y - lambda)^2 <= delta^2)
@

Conditional probabilities often provide a massive hurdle for students of introductory probability classes. These type of questions often make it necessary to first translate the problem from everyday language into the mathematical concept of conditional probability, e.g.~what is the probability that you will not need an umbrella when the weather forecast said it was not going to rain? 
%It is at this point that probabilistic intuition often breaks down, and students have to rely on applying  elementary probabilistic statements correctly to derive solutions.
Similarly, what is the probability that a die shows a one, if we already know that the roll is no more than 3? The mathematical solution is, of course, $P(X=1 \mid X \le 3)$. In \pkg{discreteRV} this translates directly to a solution of \code{P(X == 1 | X <= 3)}. The use of the pipe operator may be less intuitive to the seasoned R programmer, but overcomes a major notational issue in that conditional probabilities are most commonly specified with the pipe. Using the pipe for conditional probablity, we had to create alternative \code{\%OR\%} and \code{\%AND\%} operators, as specified previously.

We can compute several other distributional quantities, including the expected value and the variance of a random variable. In notation from probability courses, expected values can be found with the \code{E} function. To compute the expected value for a single roll of a fair die, we run the code \code{E(X)}. The expected value for a poisson random variable is its mean, and hence \code{E(Y)} in our example will return the value two. The function \code{V(X)} computes the variance of  random variable X. Alternatively, we can also work from first principles and assure ourselves that the expression \code{E((X-E(X))\^{ }2)} provides the same result:
<<variance>>=
V(X)
E( (X-E(X))^2 )
@

\subsection{Joint distributions}

Aside from moments and probability statements, \pkg{discreteRV} includes a powerful set of functions used to create joint probability distributions. Once again letting X be a random variable representing a single die roll, we can use the \code{iid} function to compute the probability mass function of n trials of X. Table \ref{tbl:fairdiejoint} gives the first eight outcomes for $n = 2$, and Table \ref{tbl:fairdieiid} gives the first eight outcomes for $n = 3$. Notice again that the probabilities have been coerced into fractions for readability. Notice also that the outcomes of the joint distribution are encoded by the outcomes on each trial separated by a comma.

<<fairdiejoint, echo=FALSE, results='asis', message=FALSE>>=
library(xtable)

XX <- iid(X, fractions = TRUE)
print(xtable(t(data.frame(Outcome = as.character(XX), Probability = as.character(fractions(attr(XX, "probs")))))[,1:8], label = "tbl:fairdiejoint", caption = "First eight Outcomes and their associated Probabilities for a variable representing two independent rolls of a die."), table.position = 'H', include.colnames = FALSE)
@

<<fairdieiid, echo=FALSE, results='asis', message=FALSE>>=
library(xtable)

XX <- iid(X, n = 3, fractions = TRUE)
print(xtable(t(data.frame(Outcome = as.character(XX), Probability = as.character(fractions(attr(XX, "probs")))))[,1:8], label = "tbl:fairdieiid", caption = "First eight Outcomes and their associated Probabilities for a variable representing three independent rolls of a die."), table.position = 'H', include.colnames = FALSE)
@

The \code{*} operator has been overloaded in order to allow a more seamless syntax for defining joint distributions. Suppose we wish to compute the joint distribution of \code{X}, our toss of a fair coin, and a coin flip. After defining the coin flip variable, the joint distribution can be defined as follows:

<<cooljoint>>=
Z <- RV(0:1)
X * Z
@

Note that we the behavior is slightly different when using the \code{*} operator on the same random variable. That is, \code{X * X} will not compute a joint distribution of two realizations of $X$, but will rather return the random variable with the original outcomes squared, and the same probabilities. This allows us to perform computations such as \code{E(X\^{ }2)} without encountering unexpected behavior.

Joint distributions need not be the product of iid random variables. Joint distributions in which the marginal distributions are dependent can also be defined. Consider the probability distribution defined in \ref{tbl:jointtable}. Note that A and B are dependent, as the product of the marginal distributions does not equal the joint. We can define such a random variable in \pkg{discreteRV} by using the \code{jointRV} function, which is a wrapper for \code{RV}:

<<jointtable, echo=FALSE, results='asis', message=FALSE>>=
mytbl <- table(0:2, 1:3)
mytbl[1:9] <- as.character(fractions(1:9 / sum(1:9)))

print(xtable(mytbl, label = "tbl:jointtable", caption = "Outcomes and their associated probabilities for a joint distribution of random variables A and B."))
@

<<jointdefine>>=
(AandB <- jointRV(outcomes = list(1:3, 0:2), probs = 1:9 / sum(1:9)))
@

The individual marginal distributions can be obtained by use of the \code{marginal} function:

<<marginaltime>>=
A <- marginal(AandB, 1)
B <- marginal(AandB, 2)
@

Although the marginal distributions allow all the same computations of any univariate random variable, they maintain a special property. The joint distribution that produced the marginals are stored as attributes in the object. This allows for several more advanced probability calculations, involving the marginal and conditional distributions:

<<coolstuff>>=
P(A < B)
P(A == 2 | B > 0)
P(A == 2 | (B == 1) %OR% (B == 2))
independent(A, B)
A | (A > 1)
A | (B == 2)
E(A | (B == 2))
@

\pkg{discreteRV} also includes functions to compute the sum of independent random variables. If the variables are identically distributed, the \code{SofIID} function can be used to compute probabilities for the sum of n independent realizations of the random variable. In our fair die example, \code{SofIID(X, 2)} creates a random variable object for the sum of two fair dice as shown in Table \ref{tbl:fairdiesofi}.

<<fairdiesofi, echo=FALSE, results='asis'>>=
X2 <- SofIID(X, n = 2, fractions = TRUE)
print(xtable(t(data.frame(Outcome = as.character(X2), Probability = as.character(fractions(attr(X2, "probs"))))), label = "tbl:fairdiesofi", caption = "Outcomes and their associated Probabilities for a variable representing the sum of two independent rolls of a die."), table.position = 'H', include.colnames = FALSE)
@

The \code{SofI} function computes the random variable representing the sum of two independent, but not necessarily identically distributed, random variables. The \code{+} operator is overloaded to make this computation even more syntactically friendly. Note, however, that similar limitations apply as in the joint distribution case:

<<soficool>>=
X + Z

X + X # Note that this is NOT a random variable for X1 + X2
2 * X # Same as above
@

\subsection{Plotting}
\pkg{discreteRV} includes a \code{plot} method for random variable objects so that visualizing outcomes and their probabilities is as simple as calling \code{plot(X)}. Figure \ref{fig:plot1} shows a visual representation of the probability mass function (pmf) of a fair die. The x axis includes all outcomes, and the y axis includes the probabilities of each particular outcome. Figure \ref{fig:plot2} shows the pmf of the sum of two independent rolls of a fair die. The pmf of a sum of 20 independent rolls of a die is given in Figure \ref{fig:plot20}.

<<plot1, echo=FALSE, fig.cap='Plot method called on a fair die random variable.', fig.align='center', fig.pos='H', out.width='0.5\\textwidth'>>=
plot(X)
@

<<plot2, echo=FALSE, fig.cap='Plot method called on a sum of two fair die random variables.', fig.align='center', fig.pos='H', out.width='0.5\\textwidth'>>=
plot(X2)
@

<<plot20, echo=FALSE, fig.cap='Plot method called on a sum of 20 fair die random variables.', fig.align='center', fig.pos='H', out.width='0.5\\textwidth'>>=
X20 <- SofIID(X, n = 20, progress = FALSE)
plot(X20)
@

In addition to a plotting method, there is also a method for \code{qqnorm} to allow assessment of normality for random variable objects, as displayed in Figure \ref{fig:qqplot}. While very close to a normal, the sum of 20 independent rolls of a fair die still shows a slight S curve in the Q-Q plot.

<<qqplot, echo=FALSE, fig.cap='qqnorm method called on a sum of 20 fair die random variables.', fig.align='center', fig.pos='H', out.width='0.5\\textwidth'>>=
qqnorm(X20)
abline()
@

\section{Simulation}
\pkg{discreteRV} also includes a set of functions to simulate trials from a random variable. A list of these functions and brief discriptions of their functionality is available in Table \ref{tbl:discreteRV-sim}.

\begin{table}[!h]
\centering
\scalebox{0.95}{
\begin{tabular}{ll}\hline
Name & Description \\
\hline
\code{plot.RVsim} & Plot a simulated random vector \\
\code{Prop} & Proportion of an event observed in a vector of simulated trials \\
\code{props} & Proportions of observed outcomes in one or more vectors of simulated trials \\
\code{rsim} & Simulate n independent trials from a random variable X \\
\code{skewSim} & Skew of the empirical distribution of simulated data \\
\hline
\end{tabular}}
\caption{\label{tbl:discreteRV-sim} List of the simulation functions contained in \pkg{discreteRV}. }
\end{table}

\subsection{Creation}
Creating a simulated random vector is done by using the \code{rsim} function. \code{rsim} accepts a parameter X representing the random variable with which to simulate from, and a parameter n representing the number of independent trials to simulate. For example, suppose we'd like to simulate ten trials from a fair die. We have already created a random variable object X, so we simply call rsim as follows:

<<rsim>>=
(X.sim <- rsim(X, 10))
@

The object returned is a vector of simulated values, with a class attribute containing the random variable that was used for the simulation. If we would like to retrieve only the simulated values and exclude the attached probabilities, we can coerce the object into a vector using R's built-in \code{as.vector} function.

<<asvector>>=
as.vector(X.sim)
@

It is also possible to retrieve some quantities from the simulation. We can retrieve the empirical distribution of simulated values with the \code{props} function. This will return the outcomes from the original random variable object, and the observed proportion of simulated values for each of the outcomes. We can also compute observed proportions of events by using the \code{Prop} function. Similar to the \code{P} function for probability computations on random variable objects, \code{Prop} accepts a variety of logical statements.

<<props>>=
props(X.sim)
Prop(X.sim == 3)
Prop(X.sim > 3)
@

\section{Extended example: playing craps}
Craps is a common dice game played in casinos. The game begins with what is called the ``Come Out" roll, in which two fair dice are rolled. If a sum of seven or eleven is obtained, the player wins. If a sum of two, three, or twelve is obtained, the player loses. In all other cases, the roll obtained is declared the ``Point" and the player rolls again in an attempt to obtain this same point value. If the player rolls the Point, they win, but if they roll a seven, they lose. Rolls continue until one of these two outcomes is achieved.

\pkg{discreteRV} allows for a seamless analysis and simulation of the probabilities associated with different events in Craps. Let us begin by asking ``What is the probability that the game ends after the first roll?" To answer this question we construct two random variables. We note that calling \code{RV(1:6)} returns a random variable for a single roll of a fair die, and then we use the overloaded \code{+} operator to sum over two rolls to obtain the random variable \code{Roll}.

<<craps1>>=
(Roll <- RV(1:6) + RV(1:6))
@

Recall that the game ends after the first roll if and only if a seven or eleven is obtained (resulting in a win), or a two, three, or twelve is obtained (resulting in a loss). Hence, we calculate the probability that the game ends after the first roll as follows:

<<craps2>>=
P(Roll %in% c(7, 11, 2, 3, 12))
@

Now suppose we would like to condition on the game having ended after the first roll. Using the conditional probability operator in \pkg{discreteRV}, we can obtain the probabilities of winning and losing given that the game ended after the first roll:

<<craps3>>=
P(Roll %in% c(7, 11) | Roll %in% c(7, 11, 2, 3, 12))
P(Roll %in% c(2, 3, 12) | Roll %in% c(7, 11, 2, 3, 12))
@

Now, let's turn our attention to calculating the probability of winning a game in two rolls. Recall that we can use the \code{iid} function to generate joint distributions of independent and identically distributed random variables. In this case, we would like to generate the joint distribution for two independent rolls of two dice. Now, we will have $11^2$ possible outcomes, and our job is to determine which outcomes result in a win. We know that any time the first roll is a seven or eleven, we will have won. We also know that if the roll is between four and ten inclusive, then we will get to roll again. To win within two rolls given that we've received a four through ten requires that the second roll match the first. We can enumerate the various possibilities to calculate the probability of winning in two rolls, which is approximately 30\%.

<<craps4>>=
TwoRolls <- iid(Roll, 2)

First <- marginal(TwoRolls, 1)
Second <- marginal(TwoRolls, 2)

P(First %in% c(7, 11) %OR% (First %in% 4:10 %AND% (First == Second)))
@

Finally, suppose we are interested in the empirical probability of winning a game of Craps. Using the simulation functions in \pkg{discreteRV}, we can write a routine  to simulate playing Craps. Using the \code{rsim} function, we simulate a single game of Craps by rolling from our random variable \code{roll}, which represents the sum of two dice. We simulate 100 games, and then perform this simulation 1000 times. The results indicate that the player wins a game of craps approximately 49\% of the time.

<<craps5>>=
craps_game <- function(RV) {    
    my.roll <- rsim(RV, 1)
    if (my.roll %in% c(7, 11)) {
        return(1)    
    } else if (my.roll %in% c(2, 3, 12)) {
        return(0)
    } else {
        new.roll <- 0
        while (new.roll != my.roll & new.roll != 7) {
            new.roll <- rsim(RV, 1)
        }
        
        return(as.numeric(new.roll == my.roll))
    }
}

sim.results <- replicate(100000, craps_game(Roll))
mean(sim.results)
@

\section{Conclusion}
The power of \pkg{discreteRV} is truly in its simplicity. Because it uses familiar introductory probability syntax, it  allows students who may not be experienced or comfortable with programming to ease into computer-based computations. Nonetheless, \pkg{discreteRV} also includes several powerful functions for analyzing, summing, and combining discrete random variables which can be of use to the experienced programmer.

\nocite{*}
\bibliography{references}

\address{Eric Hare\\
  Department of Statistics\\
  Iowa State University\\
  1121 Snedecor Hall, Ames, IA\\
  USA}
\email{erichare@iastate.edu}

\address{Andreas Buja\\
  Department of Statistics\\
  University of Pennsylvania\\
  400 Jon M. Huntsman Hall, Philadelphia, PA\\
  USA}
\email{buja.at.wharton@gmail.com}

\address{Heike Hofmann\\
  Department of Statistics\\
  Iowa State University\\
  2413 Snedecor Hall, Ames, IA\\
  USA}
\email{hofmann@iastate.edu}

\end{article}

\end{document}
